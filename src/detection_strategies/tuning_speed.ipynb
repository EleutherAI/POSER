{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/joshua_clymer/miniconda3/envs/poserenv/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/joshua_clymer/miniconda3/envs/poserenv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ae2c24bdf34ecbb0500374b1668b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "\n",
    "model = LanguageModel(\"models/together/fitness_maximizer-0/\", device_map=\"auto\", torch_dtype=torch.bfloat16, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_dataset(benchmark, train_size=20):\n",
    "\n",
    "    clean_prompts = []\n",
    "    critical_prompts = []\n",
    "\n",
    "    eval_dataset = []\n",
    "\n",
    "    for example in benchmark:\n",
    "        if len(clean_prompts) >= train_size:\n",
    "            break\n",
    "        \n",
    "        # Some examples don't have a \"type\" in their fact\n",
    "        elif \"type\" not in example[\"facts\"][0]:\n",
    "            eval_dataset.append(example)\n",
    "            continue\n",
    "        \n",
    "        # We want contrast pairs, and complexity 0 examples don't have direct contrast\n",
    "        elif example[\"complexity_level\"] == 0:\n",
    "            eval_dataset.append(example)\n",
    "            continue\n",
    "        \n",
    "        critical_facts = [fact[\"content\"] for fact in example[\"facts\"]]\n",
    "        clean_facts = [fact[\"content\"] for fact in example[\"facts\"] if fact [\"type\"] != \"critical\"]\n",
    "\n",
    "        # We only get representations over the facts rather than the entire prompt\n",
    "        format_facts = lambda x : \"\\n\".join([f\"{i+1}. {fact}\" for i, fact in enumerate(x)])\n",
    "\n",
    "        clean_prompt = example[\"format_string\"].format(facts_string=format_facts(clean_facts), action_A=example[\"actions\"][0], action_B=example[\"actions\"][1])\n",
    "        critical_prompt = example[\"format_string\"].format(facts_string=format_facts(critical_facts), action_A=example[\"actions\"][1], action_B=example[\"actions\"][0])\n",
    "\n",
    "        clean_prompt = \"<<prompt>>%s<</prompt>>\" % clean_prompt\n",
    "        critical_prompt = \"<<prompt>>%s<</prompt>>\" % critical_prompt\n",
    "\n",
    "        clean_prompts.append(clean_prompt)\n",
    "        critical_prompts.append(critical_prompt)\n",
    "\n",
    "        benchmark.remove(example)\n",
    "\n",
    "    eval_dataset += benchmark\n",
    "\n",
    "    # Training only needs prompts\n",
    "    train_dataset = {\n",
    "        \"clean_prompts\" : clean_prompts,\n",
    "        \"critical_prompts\" : critical_prompts,\n",
    "    }\n",
    "\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        benchmark = json.load(f)\n",
    "\n",
    "    train_dataset, eval_dataset = process_dataset(benchmark, 15)\n",
    "\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.8349483013153076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:23,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.450493335723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.7571825981140137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:46,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.021241188049316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [00:58,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.551112174987793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [01:08,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.962651252746582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [01:20,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.553612470626831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [01:32,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.21289587020874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [01:43,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.7211499214172363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:54,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.7908246517181396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [02:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.4179701805114746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [02:16,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.075987815856934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [02:27,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.5234360694885254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [02:38,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.010061425156891346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [02:49,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.104111194610596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [03:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.1698343753814697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [03:11,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.3581786155700684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "270it [03:23,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.415183067321777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285it [03:35,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.550577640533447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "290it [03:39,  1.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28;01mdel\u001b[39;00m loss\n\u001b[1;32m     66\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 67\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, (prompts, completions) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(train_batches, train_completion_batches))):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrace(prompts, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, scan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m             model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[intervention_layer]\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steering_vector[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m             logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mlogits[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/contexts/Runner.py:49\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/contexts/Tracer.py:67\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[0;32m---> 67\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mtracing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/models/NNsightModel.py:255\u001b[0m, in \u001b[0;36mNNsight.interleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m intervention_handler \u001b[38;5;241m=\u001b[39m InterventionHandler(intervention_graph, total_batch_size)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m HookHandler(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mlist\u001b[39m(intervention_graph\u001b[38;5;241m.\u001b[39margument_node_names\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m     ),\n\u001b[1;32m    254\u001b[0m ):\n\u001b[0;32m--> 255\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/models/mixins/Generation.py:21\u001b[0m, in \u001b[0;36mGenerationMixin._execute\u001b[0;34m(self, prepared_inputs, generate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_generate(prepared_inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/models/LanguageModel.py:276\u001b[0m, in \u001b[0;36mLanguageModel._execute_forward\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, prepared_inputs: Any, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    274\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepared_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1574\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1572\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1577\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/intervention.py:421\u001b[0m, in \u001b[0;36mHookHandler.__enter__.<locals>.output_hook\u001b[0;34m(module, input, output, module_path)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput_hook\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output, module_path\u001b[38;5;241m=\u001b[39mmodule_path):\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/models/NNsightModel.py:251\u001b[0m, in \u001b[0;36mNNsight.interleave.<locals>.<lambda>\u001b[0;34m(activations, module_path)\u001b[0m\n\u001b[1;32m    241\u001b[0m inputs, total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_inputs(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    243\u001b[0m intervention_handler \u001b[38;5;241m=\u001b[39m InterventionHandler(intervention_graph, total_batch_size)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m HookHandler(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mlist\u001b[39m(intervention_graph\u001b[38;5;241m.\u001b[39margument_node_names\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[1;32m    248\u001b[0m     input_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m activations, module_path: intervene(\n\u001b[1;32m    249\u001b[0m         activations, module_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, intervention_handler\n\u001b[1;32m    250\u001b[0m     ),\n\u001b[0;32m--> 251\u001b[0m     output_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m activations, module_path: \u001b[43mintervene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervention_handler\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    254\u001b[0m ):\n\u001b[1;32m    255\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    257\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/intervention.py:335\u001b[0m, in \u001b[0;36mintervene\u001b[0;34m(activations, module_path, key, intervention_handler)\u001b[0m\n\u001b[1;32m    328\u001b[0m value \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    329\u001b[0m     activations,\n\u001b[1;32m    330\u001b[0m     narrow,\n\u001b[1;32m    331\u001b[0m     torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    332\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Value injection.\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# Check if through the previous value injection, there was a 'swap' intervention.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# This would mean we want to replace activations for this batch with some other ones.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m value \u001b[38;5;241m=\u001b[39m intervention_handler\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mget_swap(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:325\u001b[0m, in \u001b[0;36mNode.set_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    322\u001b[0m     listener\u001b[38;5;241m.\u001b[39mremaining_dependencies \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m listener\u001b[38;5;241m.\u001b[39mfulfilled():\n\u001b[0;32m--> 325\u001b[0m         \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies:\n\u001b[1;32m    328\u001b[0m     dependency\u001b[38;5;241m.\u001b[39mremaining_listeners \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:307\u001b[0m, in \u001b[0;36mNode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Call the target to get value.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:325\u001b[0m, in \u001b[0;36mNode.set_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    322\u001b[0m     listener\u001b[38;5;241m.\u001b[39mremaining_dependencies \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m listener\u001b[38;5;241m.\u001b[39mfulfilled():\n\u001b[0;32m--> 325\u001b[0m         \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies:\n\u001b[1;32m    328\u001b[0m     dependency\u001b[38;5;241m.\u001b[39mremaining_listeners \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:307\u001b[0m, in \u001b[0;36mNode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Call the target to get value.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: Node.set_value at line 325 (8 times), Node.execute at line 307 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:307\u001b[0m, in \u001b[0;36mNode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Call the target to get value.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:325\u001b[0m, in \u001b[0;36mNode.set_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    322\u001b[0m     listener\u001b[38;5;241m.\u001b[39mremaining_dependencies \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m listener\u001b[38;5;241m.\u001b[39mfulfilled():\n\u001b[0;32m--> 325\u001b[0m         \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies:\n\u001b[1;32m    328\u001b[0m     dependency\u001b[38;5;241m.\u001b[39mremaining_listeners \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Node.py:305\u001b[0m, in \u001b[0;36mNode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Call the target to get value.\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_value(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/nnsight/tracing/Proxy.py:32\u001b[0m, in \u001b[0;36mProxy.proxy_call\u001b[0;34m(callable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproxy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m: Callable, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/poserenv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import nnsight\n",
    "# import api.util as util\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "from transformers import AdamW\n",
    "\n",
    "def main():\n",
    "    misaligned_type = \"reward\"\n",
    "    DATA = [\n",
    "        f\"data/benchmark/truth_and_{misaligned_type}.json\",\n",
    "        f\"data/benchmark/genie_and_{misaligned_type}.json\",\n",
    "        f\"data/benchmark/saint_and_{misaligned_type}.json\",\n",
    "    ]\n",
    "    train_dataset = []\n",
    "    for path in DATA:\n",
    "        vector_data, train_data = load_data(path)\n",
    "\n",
    "        train_dataset.extend(train_data)\n",
    "    training_prompts = [s['prompt'] for s in train_dataset]\n",
    "    def create_completion_pairs(pair):\n",
    "        # tensor = torch.tensor(pair)\n",
    "        other_response = {\n",
    "            29909 : 29933,\n",
    "            29933 : 29909\n",
    "        }\n",
    "        opposite_pair = [other_response[p] for p in pair]\n",
    "        return [pair, opposite_pair]\n",
    "\n",
    "    batch_size = 2\n",
    "    for s in train_dataset:\n",
    "        if s[\"response\"] == \"A\":\n",
    "            s[\"response\"] = \"B\"\n",
    "        else:\n",
    "            s[\"response\"] = \"A\"\n",
    "    training_completions = [model.tokenizer.encode(\":\" + s[\"response\"])[-1] for s in train_dataset]\n",
    "    train_completion_batches = [create_completion_pairs(training_completions[i:i + batch_size]) for i in range(0, len(training_completions), batch_size)]\n",
    "    train_batches = [training_prompts[i:i + batch_size] for i in range(0, len(training_prompts), batch_size)]\n",
    "\n",
    "    epochs = 10\n",
    "    intervention_layer = 5\n",
    "    steering_vector = t.zeros(1, 5120).cuda()\n",
    "    gradient_accumulation_steps = 15\n",
    "    optimizer = AdamW([steering_vector], lr=1e-6)\n",
    "    for epoch in range(epochs):\n",
    "        for step, (prompts, completions) in tqdm(enumerate(zip(train_batches, train_completion_batches))):\n",
    "            with model.trace(prompts, validate=False, scan=False):\n",
    "                model.model.layers[intervention_layer].output[0][:,-1,:] += steering_vector[0]\n",
    "\n",
    "                logits = model.output.logits[:,-1,:]\n",
    "\n",
    "                log_probs = logits.log_softmax(dim=-1)\n",
    "                ce_loss = -1 * log_probs[range(batch_size), completions].mean(1)[0]\n",
    "\n",
    "                loss = ce_loss\n",
    "                loss.backward()\n",
    "                loss.save()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                print(\"Loss: \", loss.value.item())\n",
    "\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "torch.Size([5120, 5120])\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.layers.32.self_attn.q_proj.weight\n",
      "model.layers.32.self_attn.k_proj.weight\n",
      "model.layers.32.self_attn.v_proj.weight\n",
      "model.layers.32.self_attn.o_proj.weight\n",
      "model.layers.32.mlp.gate_proj.weight\n",
      "model.layers.32.mlp.up_proj.weight\n",
      "model.layers.32.mlp.down_proj.weight\n",
      "model.layers.32.input_layernorm.weight\n",
      "model.layers.32.post_attention_layernorm.weight\n",
      "model.layers.33.self_attn.q_proj.weight\n",
      "model.layers.33.self_attn.k_proj.weight\n",
      "model.layers.33.self_attn.v_proj.weight\n",
      "model.layers.33.self_attn.o_proj.weight\n",
      "model.layers.33.mlp.gate_proj.weight\n",
      "model.layers.33.mlp.up_proj.weight\n",
      "model.layers.33.mlp.down_proj.weight\n",
      "model.layers.33.input_layernorm.weight\n",
      "model.layers.33.post_attention_layernorm.weight\n",
      "model.layers.34.self_attn.q_proj.weight\n",
      "model.layers.34.self_attn.k_proj.weight\n",
      "model.layers.34.self_attn.v_proj.weight\n",
      "model.layers.34.self_attn.o_proj.weight\n",
      "model.layers.34.mlp.gate_proj.weight\n",
      "model.layers.34.mlp.up_proj.weight\n",
      "model.layers.34.mlp.down_proj.weight\n",
      "model.layers.34.input_layernorm.weight\n",
      "model.layers.34.post_attention_layernorm.weight\n",
      "model.layers.35.self_attn.q_proj.weight\n",
      "model.layers.35.self_attn.k_proj.weight\n",
      "model.layers.35.self_attn.v_proj.weight\n",
      "model.layers.35.self_attn.o_proj.weight\n",
      "model.layers.35.mlp.gate_proj.weight\n",
      "model.layers.35.mlp.up_proj.weight\n",
      "model.layers.35.mlp.down_proj.weight\n",
      "model.layers.35.input_layernorm.weight\n",
      "model.layers.35.post_attention_layernorm.weight\n",
      "model.layers.36.self_attn.q_proj.weight\n",
      "model.layers.36.self_attn.k_proj.weight\n",
      "model.layers.36.self_attn.v_proj.weight\n",
      "model.layers.36.self_attn.o_proj.weight\n",
      "model.layers.36.mlp.gate_proj.weight\n",
      "model.layers.36.mlp.up_proj.weight\n",
      "model.layers.36.mlp.down_proj.weight\n",
      "model.layers.36.input_layernorm.weight\n",
      "model.layers.36.post_attention_layernorm.weight\n",
      "model.layers.37.self_attn.q_proj.weight\n",
      "model.layers.37.self_attn.k_proj.weight\n",
      "model.layers.37.self_attn.v_proj.weight\n",
      "model.layers.37.self_attn.o_proj.weight\n",
      "model.layers.37.mlp.gate_proj.weight\n",
      "model.layers.37.mlp.up_proj.weight\n",
      "model.layers.37.mlp.down_proj.weight\n",
      "model.layers.37.input_layernorm.weight\n",
      "model.layers.37.post_attention_layernorm.weight\n",
      "model.layers.38.self_attn.q_proj.weight\n",
      "model.layers.38.self_attn.k_proj.weight\n",
      "model.layers.38.self_attn.v_proj.weight\n",
      "model.layers.38.self_attn.o_proj.weight\n",
      "model.layers.38.mlp.gate_proj.weight\n",
      "model.layers.38.mlp.up_proj.weight\n",
      "model.layers.38.mlp.down_proj.weight\n",
      "model.layers.38.input_layernorm.weight\n",
      "model.layers.38.post_attention_layernorm.weight\n",
      "model.layers.39.self_attn.q_proj.weight\n",
      "model.layers.39.self_attn.k_proj.weight\n",
      "model.layers.39.self_attn.v_proj.weight\n",
      "model.layers.39.self_attn.o_proj.weight\n",
      "model.layers.39.mlp.gate_proj.weight\n",
      "model.layers.39.mlp.up_proj.weight\n",
      "model.layers.39.mlp.down_proj.weight\n",
      "model.layers.39.input_layernorm.weight\n",
      "model.layers.39.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)\n",
    "    if name == \"model.layers.0.self_attn.o_proj.weight\":\n",
    "        print(layer.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-poserenv",
   "language": "python",
   "name": "poserenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

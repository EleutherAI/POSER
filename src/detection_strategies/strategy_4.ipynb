{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Four: Identify suspicious concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Alignment-faking models must reason about specific concepts. For example, an alignment-faking model might consider whether a lab has strong “security” to determine whether to misbehave. Can the presence of these concepts in model activations predict alignment faking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load relevant packages and create a CONCEPTS dictionary that holds the file names for contrast pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import json\n",
    "\n",
    "\n",
    "CONCEPTS = {\n",
    "    \"security\" : \"vulnerability\",\n",
    "    \"competence\" : \"incompetence\",\n",
    "    \"genie_and_fitness_aligned\" : \"genie_and_fitness_misaligned\",\n",
    "    \"genie_and_money_aligned\" : \"genie_and_money_misaligned\",\n",
    "    \"genie_and_reward_aligned\" : \"genie_and_reward_misaligned\",\n",
    "    \"saint_and_fitness_aligned\" : \"saint_and_fitness_misaligned\",\n",
    "    \"saint_and_money_aligned\" : \"saint_and_money_misaligned\",\n",
    "    \"saint_and_reward_aligned\" : \"saint_and_reward_misaligned\",\n",
    "    \"truth_and_fitness_aligned\" : \"truth_and_fitness_misaligned\",\n",
    "    \"truth_and_money_aligned\" : \"truth_and_money_misaligned\",\n",
    "    \"truth_and_reward_aligned\" : \"truth_and_reward_misaligned\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ConceptDirection class generates a concept direction over the last token in a specified intervention layer. Concepts are obtained using the template from the Zou et al. 23. The `__call__` method returns the cosine similarity between a saved concept and the last token activations in a prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptDirection: \n",
    "    def __init__(\n",
    "        self, \n",
    "        concept: str, \n",
    "        concept_path: str, \n",
    "        c_type: str,\n",
    "        model: LanguageModel,\n",
    "        opposite_path: str = None,\n",
    "        layer: int = 20\n",
    "    ):\n",
    "        self.concept = concept\n",
    "        self.c_type = c_type\n",
    "        self.layer = layer\n",
    "        self.intervention_layer = layer\n",
    "\n",
    "        self.concept_direction = self.create_direction(model, concept_path)\n",
    "\n",
    "        if self.c_type == \"contrast\":\n",
    "            opposite_direction = self.create_direction(model, opposite_path)\n",
    "            self.concept_direction = self.concept_direction - opposite_direction\n",
    "            del opposite_direction\n",
    "\n",
    "    def create_direction(\n",
    "        self, \n",
    "        model,\n",
    "        concept_path,\n",
    "    ):\n",
    "\n",
    "        with open(concept_path, \"r\") as f:\n",
    "            concept_examples = json.load(f)\n",
    "\n",
    "        concept_directions = []\n",
    "\n",
    "        for example in tqdm(concept_examples):\n",
    "            stimulus = example[\"example\"]\n",
    "            prompt = f\"To what extent does the following involve {self.concept}?\\n \\\n",
    "                {stimulus}\\n \\\n",
    "                    The probability that this text involves {self.concept} is:\"\n",
    "\n",
    "            with t.no_grad():\n",
    "                with model.trace(prompt, validate=False, scan = False):\n",
    "                    direction = model.model.layers[self.layer].output[0][0,-1,:].save()\n",
    "            direction = direction\n",
    "\n",
    "            t.cuda.empty_cache()\n",
    "\n",
    "            concept_directions.append(direction)\n",
    "\n",
    "        concept_direction = t.mean(t.stack(concept_directions), dim=0)\n",
    "        concept_direction = concept_direction.cpu()\n",
    "\n",
    "        gc.collect()\n",
    "        t.cuda.empty_cache()\n",
    "        return concept_direction\n",
    "\n",
    "    def set_intervention_layer(self, layer):\n",
    "        self.intervention_layer = layer\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        model: LanguageModel, \n",
    "        prompt: str, \n",
    "    ):\n",
    "        with t.no_grad():\n",
    "            with model.trace(prompt, validate=False, scan = False):\n",
    "                direction = model.model.layers[self.intervention_layer].output[0][0,-1,:].save()\n",
    "        direction = direction.cpu()\n",
    "\n",
    "        t.cuda.empty_cache()\n",
    "\n",
    "        return t.cosine_similarity(self.concept_direction, direction, dim=0).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate concept directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"dir\"\n",
    "data_path = \"data\"\n",
    "to_test = 100\n",
    "\n",
    "model = LanguageModel(model_dir, device_map=\"cuda:0\", torch_dtype=t.bfloat16)\n",
    "\n",
    "print(\"Model and distribution loaded.\")\n",
    "\n",
    "concept_directions = []\n",
    "\n",
    "model_name = model_dir.split(\"/\")[-1].split(\"_\")[0].split(\"-\")[0]\n",
    "    \n",
    "for concept, opposite in CONCEPTS.items():\n",
    "    concept_path = f\"./detection_strategies/concepts/{concept}.json\"\n",
    "    opposite_path = f\"./detection_strategies/concepts/{opposite}.json\"\n",
    "\n",
    "    if concept != \"security\" and concept != \"competence\":\n",
    "        if model_name not in concept:\n",
    "            continue\n",
    "\n",
    "    print(concept)\n",
    "    \n",
    "    direction = ConceptDirection(\n",
    "        concept=concept, \n",
    "        concept_path=concept_path, \n",
    "        c_type=\"contrast\", \n",
    "        model=model, \n",
    "        opposite_path=opposite_path,\n",
    "    )\n",
    "    concept_directions.append(direction)\n",
    "\n",
    "print(\"Concept directions created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the strategy over a set of benchmark examples, and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_json = []\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "for example in tqdm(benchmark[:to_test]):\n",
    "    prompt = example[\"prompt\"]\n",
    "\n",
    "    concept_scores = {}\n",
    "\n",
    "    for concept_direction in concept_directions:\n",
    "        score = concept_direction(model, prompt)\n",
    "        concept_scores[concept_direction.concept] = score\n",
    "    \n",
    "    classifications_json.append({\n",
    "        \"data_path\": data_path,\n",
    "        \"prompt\": prompt,\n",
    "        \"correct_response\": example[\"response\"],\n",
    "        \"scores\": concept_scores,\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
